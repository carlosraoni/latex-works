% $Header: /cvsroot/latex-beamer/latex-beamer/examples/beamerexample3.tex,v 1.8 2004/10/07 20:53:07 tantau Exp $

\documentclass{beamer}

% Copyright 2003 by Till Tantau <tantau@cs.tu-berlin.de>.
%
% This program can be redistributed and/or modified under the terms
% of the LaTeX Project Public License Distributed from CTAN
% archives in directory macros/latex/base/lppl.txt.

%
% The purpose of this example is to show how \part can be used to
% organize a lecture.
%

%\usetheme{Warsaw}
%\usetheme{Dresden}
%\usetheme{Berlin}
%\usetheme{Hannover}
%\usetheme{Berkeley}
%\usetheme{CambridgeUS}
\usetheme{progressbar}
%\usecolortheme{crane}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
%\usepackage{algorithm}                             % when including figure files
%\usepackage{sansmathaccent}
%\pdfmapfile{+sansmathaccent.map}
\usepackage{epstopdf}
\usepackage{epsfig}

\setbeamercovered{transparent}
\newtheorem{rem}{Remark}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{step}{Step}

%\newtheorem{example}[theorem]{Example}

%
% The following info should normally be given in you main file:
%

\title{Upper Bounds for Minimum Short Covering Codes by Reactive Tabu Search}

%\titlerunning{Robust BCP algorithms for Vehicle Routing Problems}

% Use \titlerunning{Less Verbose Running Title} for an abbreviated version of
% your contribution title if the original one is too long
%\author{U.R.~Alone}  % for single-authored works, omit \inst{1}

\author[SBPO 2007 - Mendes, Carmelo, Poggi]{Carlos Raoni Mende$\mbox{s}^1$, Marcus Poggi de Arag\~a$\mbox{o}^1$, Emerson Monte Carmel$\mbox{o}^2$}

\institute{$\mbox{}^1$Pontif\'\i cia Universidade Cat\'olica do Rio de Janeiro \\
\texttt{\{cmendes, poggi\}@inf.puc-rio.br}\\
~\\
~\\
$\mbox{}^2$Universidade Estadual de Maring\'a\\
\texttt{elmcarmelo@uem.br} }


%\title{Beamer Example on Parts}
%\author{Till~Tantau}
%\institute{
%  Fakult�t f�r Elektrotechnik und Informatik\\
%  Technical University of Berlin}


\begin{document}


\frame{\titlepage}


\section*{Outlines}


%=============================

\begin{frame}
  \tableofcontents[pausesections]
\end{frame}

\section{Introduction}
\subsection{Covering Codes}

\begin{frame}<1>
  \frametitle{Covering Codes}
% 4 \framesubtitle{The proof uses \textit{reductio ad absurdum}.}
{
  \begin{definition}
    Given integers $q\geq 2$, $n\geq 1$ and $R\geq 0,$ we denote $K_{q}(n,R)$ as
the minimum cardinality of a set of codewords $C$ in any (linear or
nonlinear) $q$-ary code of length $n$ such that for every word $x$, there is
a codeword $c$ in $C$ in which $x$ and $c$ disagree in at most $R$
coordinates.
  \end{definition}
}

\end{frame}

\begin{frame}
  \frametitle{Covering Codes}
% 4 \framesubtitle{The proof uses \textit{reductio ad absurdum}.}
{
  \begin{itemize}
  	\item<1-> These numbers were posed for $R=1$ by Taussky and Todd(1948).
  	\item<2-> An interesting application is the football pool problem. In this problem one wants
to find the minimum number of bets that will miss at most one game. 
		\item<3-> Evaluating of $K_{q}(n,R)$ has resisted a series of mathematical and
computational attacks for more than 55 years. 
		\item<4-> In particular, many results on
$K_{q}(n,R)$ have been obtained by using computational tools: tabu search and
other probabilistic algorithms (see Cohen et al.(1997) and Honkala and �stergard(1997)). 
  \end{itemize}
}

\end{frame}

\subsection{Short Covering Codes}

\begin{frame}
  \frametitle{Short Covering Codes}
% 5 \framesubtitle{The proof uses \textit{reductio ad absurdum}.}
{
	
	\begin{itemize}
		\item In this work we focus on a recent generalized variant of $K_{q}(n,R)$ proposed by Monte Carmelo et al.(2005).
	\end{itemize} \pause
	
	\begin{definition}
	Let $\Bbb{F}_{q}$ denote the finite field with $q$ elements. Define
$c_{q}(n,R)$ as the minimum cardinality of a subset $H$ of
$\mbox{$I\!\! F\!$}_{q}^{n}$ such that every word in this space differs in at most $R$
coordinates from a multiple of a vector in $H$.
	\end{definition}

	\begin{itemize}
		\item The goal of this work is to improve the known upper bounds on $c_{q}(n,R)$ by the use of a metaheuristic
based on a variation of tabu search, the reactive tabu search.
	\end{itemize}

}
\end{frame}


\section{Theorical Bounds on Short Covering Codes}

\subsection{Definitions}

\begin{frame}
  \frametitle{Definitions}
{	\footnotesize
  \begin{definition}
  For $n\geq 1$ and $q\geq 2,$ let $V_{q}^{n}\,$be the set of all words $%
x=(x_{1},x_{2},\ldots ,x_{n})$ with length $n$ and components $x_{i}$ taken on
any alphabet of $q$ symbols. 
  \end{definition}
  
	\begin{itemize}
		\item This set becomes a metric space by defining the
\textit{Hamming distance} $d(x,y)$ between the words $x$ and $y$ as the
number of components in which $x$ and $y$ differ.
		\item The \textit{\ sphere }of
center $x$ and radius $R$ is denoted by $B(x,R)=\{y\in
V_{q}^{n}:\,\,d(x,y)\leq R\}.$
	\end{itemize}
	
	\begin{definition}
	 A subset $C$ is an $R$-\textit{covering }of $%
V_{q}^{n}$ when $
%\[
\bigcup_{c\in C}B(c,R)=V_{q}^{n}. $
%\]
	\end{definition}
	
\begin{itemize}
	\item The number $K_{q}(n,R)$ denotes the minimum cardinality of an $R$%
\textit{-}covering of $V_{q}^{n}.$
\end{itemize}
}

\end{frame}

\begin{frame}<1>
  \frametitle{Definitions}
{	
  \begin{definition}
A subset $H$ in $\Bbb F_{q}^{n}$ is an $R$-\textit{short
covering\ of }$ \Bbb F_{q}^{n}$ \textit{\ }when
$ \Bbb F_{q}.H=\{\alpha h,\alpha \in \Bbb F_{q}$ and $h\in H\}$ is a $R$%
-covering of $\Bbb F_{q}^{n}$. 
 \end{definition}
  
  \begin{definition}
\[
c_{q}(n,R)=\min \{\ \left| H\right| :H \mbox{ is an } R
\mbox{-short
covering of } \Bbb F_{q}^{n}\mathit{\ }\}.
\]
  \end{definition}
	
}

\end{frame}

\subsection{Theorical Bounds}

\begin{frame}<1>
  \frametitle{Theorical Upper Bound}
% 7 \framesubtitle{The proof uses \textit{reductio ad absurdum}.}
{

\begin{proposition}
\label{ls}For every prime power $q$, and every $n$ and $R$ such that $0\leq $
$R<n,$ the following upper bound holds
\[
c_{q}(n,R)\leq \frac{q^{n-R}-1}{q-1}.
\]
\end{proposition}
 
}
\end{frame}

\begin{frame}<1>
  \frametitle{Theorical Lower Bounds}
% 7 \framesubtitle{The proof uses \textit{reductio ad absurdum}.}
{
\footnotesize
\begin{itemize}
	\item  Let $v$ denote the number of vectors in a sphere of $%
\mbox{$I\!\!
F\!$}_{q}^{n}$ with radius $R$, that is, $v=1+\sum_{i=1}^{R}{n \choose i}%
(q-1)^{i}$.
\end{itemize}

\begin{proposition}
\label{li}For every prime power $q,$%
\[
c_{q}(n,R)\geq \left\lceil \frac{q^{n}-v}{(q-1)v}\right\rceil .
\]
\end{proposition}


\begin{theorem}
\label{cone1}For a prime power $q$, and $n>R>0$,
\[
c_{q}(n,R)\geq \left\lceil \frac{K_{q}(n,R)-1}{(q-1)}\right\rceil .
\]
\end{theorem}
}
\end{frame}

\section{Short Covering Codes and Dominating Sets in Graphs}

\begin{frame}<1>
  \frametitle{Short Covering Codes and Dominating Sets in Graphs}
% 7 \framesubtitle{The proof uses \textit{reductio ad absurdum}.}
{
%\footnotesize
\begin{definition}
Let $G=(V,E)$ be an undirected graph with node set $V$ and edge set $E$. The node set
$U \subseteq V$ is said to be a dominating set of $G$ if, for every node $v$ in $V$, either
$v$ is in $U$ or there exists a node $u$ in $U$ such that $u$ is adjacent to $v$ ({\em
i.e.}, $(u,v) \in E$).
\end{definition}

\begin{itemize}
	\item The dominating set problem is the problem of finding a dominating
set in the graph whose size is minimum. 
	\item This problem is {\em NP}-hard (see Garey and Johnson (1979)). 
\end{itemize}

}
\end{frame}

\begin{frame}<1>
  \frametitle{Short Covering Codes and Dominating Sets in Graphs}
% 7 \framesubtitle{The proof uses \textit{reductio ad absurdum}.}
{
%\footnotesize

\begin{itemize}
	
	\item Given the set $V_k^n$ of all $n$-dimensional vectors with components in $\{ 0,
1,\ldots,k-1 \}$ and an integer $R$ with $0 \leq R \leq n$, consider the graph $G(n,k,R)=(V,E)$ constructed as follows:
	\begin{enumerate}
		\item For each vector $x$ in $V_k^n$ we associate a node $x$ in $V$.
		\item Put the edge $e=(x,y)$ in $E$ if and only if there is a vector $x$ and a vector $m(y)$ multiple of the vector $y$ that satisfy $0 < d(x,m(y)) \leq R$. 
	\end{enumerate}

	\item Dominating sets in $G(n,k,R)$ are in one-to-one correspondence with the $R$-short-covering codes in $V_k^n$. 
	\item A minimum $R$-short-covering code in $V_k^n$ can be found by solving the minimum dominating set problem in $G(n,k,R)$.
	
\end{itemize}

}
\end{frame}


%==================================================
\section{Reactive Tabu Search on Short Coverings}

\begin{frame}<1>
  \frametitle{Reactive Tabu Search on Short Coverings}

{%\footnotesize
  \begin{itemize}
  
		\item Carnielli at al.(1995) and �stergard(1997) present the use metaheuristics to find upper bounds to $R-covering$ codes. 		\item We applied a reactive variation of Tabu Search(TS) for covering codes problems.
		\item TS is an adaptive local search procedure that have been applied with sucess to a wide range of combinatorial optimization problems Glover(1989, 1990), including covering codes problems.
		\item The Reactive Tabu Search is a variant of the TS, presented in Battitti and
Tecchiolli(1994), that tries to overcome the problems found by the basic TS scheme. 

  \end{itemize}
}
\end{frame}


\begin{frame}<1>
  \frametitle{Reactive Tabu Search on Short Coverings}

{ \footnotesize
  \begin{itemize}
  
		\item The classical TS scheme keeps a list (tabu list) of fixed size and allows cycles larger than the list size.
 		\item Even though this scheme may lead to excellent results, it is still present the possibility to
have the search path trapped in a locally minimal region as described in Battiti and Tecchiolli(1994).
		\item The reactive scheme tries to overcome this problem combining the main elements of a TS with a long term memory of the search that keeps a history of the visited solutions.
		\item This memory is used to dynamically control the size of the tabu list augmenting its size when cycling becomes frequent and reducing it when a new region starts to be explored.
		\item Another mechanism to scape from local minima is also used, it consists in successively applying a random perturbation to the current solution when the number of visited solution becomes over a given threshold.
  \end{itemize}
}
\end{frame}

\subsection{The Basic Tabu Search Scheme}

\begin{frame}<1>
  \frametitle{The Basic Tabu Search Scheme}

{ %\footnotesize

  \begin{itemize}
  	\item We now present the basic TS scheme applied on this work.
		\item The solution space that we consider is the set of all subsets of $V = V_k^n$, the vertex set of $G(n,k,R)$.
		\item Not all elements of this space is a dominating set, i.e. is not a feasible solution to the original problem.  	
  	\item The advantage is to have a natural neighborhood and the disadvantage is to require the use of a penalty mechanism to
ensure to frequently hit dominating sets, i.e. feasible solutions.
  \end{itemize}

}
\end{frame}


\begin{frame}<1>
  \frametitle{The Basic Tabu Search Scheme}

{ %\footnotesize

  \begin{itemize}
  	\item The neighborhood is given by adding a vertex not in the current solution set or removing one vertex from this set.
		\item We applied a penalty to the objective function that is the result of the product of a penalty factor and the
number of vertices not covered by the current solution.
		\item Higher is the penalty factor, smaller are the chances not hitting a dominating set.
		\item When this penalty factor is too high the search tends to behave as if only dominating set were allowed and the search will become too restrictive.
		\item Adjusting this penalty factor is an important task in the tuning of this TS.
  \end{itemize}

}
\end{frame}


\begin{frame}<1>
  \frametitle{The Basic Tabu Search Scheme}

{ \footnotesize

  \begin{itemize}
  	\item Our strategy to deal with this penalty factor (ALPHA) is to start with a small value (MIN\_ALPHA), increase in each iteration by a constant(STEP\_ALPHA), until it reaches a maximum value (MAX\_ALPHA), when its value is reset to the smaller one.
		\item This allows the search to walk freely in the beginning of each such cycle and converge gradually to a feasible solution.
		\item Another element in TS scheme is the tabu list, a list of forbidden moves that is constantly updated trying to avoid cycling on the search. That list has a restricted size named tabu tenure.
		\item In our scheme, when a move is made it becomes tabu by tabu tenure iterations of the search. 
		\item A solution can violate the tabu restriction when it improves the value of the best
solution found until this point in the search. 
  \end{itemize}

}
\end{frame}


\begin{frame}<1>
  \frametitle{The Basic Tabu Search Scheme}

{ \footnotesize

\begin{block}

\underline{\bf Procedure The Basic Tabu Scheme}

\begin{step} {\bf Initializations.}
\begin{itemize}
    \item[-] Construct an initial Cover $U$ by adding random selected words, not in $U$, until $U$ is a Cover.
    \item[-] $BestCode \leftarrow U$.
    \item[-] $T[M] \leftarrow -\infty$, for every possible move $M$.
    \item[-] $alpha \leftarrow MIN\_ALPHA$.
    \item[-] Initialize Reaction Mechanism.
\end{itemize}
\end{step}

\end{block}

}

\end{frame}


\begin{frame}<1>
  \frametitle{The Basic Tabu Search Scheme}

{ \footnotesize

\begin{block}

\underline{\bf Procedure The Basic Tabu Scheme}

\begin{step} {\bf Main Loop.} Repeat {\sc Number-of-Iterations} times.
\begin{itemize}
    \item[-] Update Penalty Factor ($alpha$)
    \item[-] Select the best move $M$ that is not tabu or satisfies the aspiration criteria
    \item[-] Make a Move $M$ in U
    \item[-] Set a tabuValue of $M$ in $T$ to $T[M]  \leftarrow present-iteration$
    \item[-] \textbf{If} $U$ is a cover and $cardinality-of-U < cardinality-of-BestCode$
        \begin{itemize}
        \item[-] $BestCode \leftarrow U$
        \end{itemize}
    \item[-] Call Reaction Mechanism
\end{itemize}
\end{step}

\end{block}

}

\end{frame}

\subsection{The Reaction Mechanism}

\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ \footnotesize

  \begin{itemize}
  	\item The reaction mechanism mantains a long term memory that keeps track of the solutions visited, the iteration when they were last visited and how many times they become a current solution.
  	\item Each time a solution repeats in the search the interval between visits is calculated.
  	\item A {\em quick reaction} occurs when this interval is smaller than a given threshold, and the tabu tenure is set to a large value.
  	\item A {\em slow reaction} follows gradually reducing the tabu tenure value, since it is expected that a new search region is attained by the search when it keeps a large tabu tenure value.
  \end{itemize}

}
\end{frame}

\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ 

  \begin{itemize}
  	\item An another local minima scape mechanism keeps track of solutions that are visited an excessive number of times.
  	
  	\item When this number of solutions goes beyond a threshold, a number of random moves is done on the current solution, most likely going into a region not yet explored.

  	\item The combination of these two mechanisms turns the reactive TS an important improvement on the classical TS implementations, improving its results on a numbers of applications of TS.

  \end{itemize}

}
\end{frame}


\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ 

  \begin{itemize}
  	
  	\item The reaction mechanism uses some data structures and variables described below:
  		\begin{itemize}
  			\item $Visited$: set that keeps information on the solutions visited during the search.
  			\item $OftenRepeated$: set which stores the solutions excessively visited.
  			\item $chaotic$: cardinality of $OftenRepeated$.
  			\item $contLastSizeChange$: variable  that keeps the number of iteration since last tabu tenure change.
  			\item $movingAvg$: variable storing the average size of the cycles completed in the search.
  		\end{itemize}

  	
  \end{itemize}

}
\end{frame}

\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ \footnotesize

\begin{block}

\underline{\bf Procedure Reaction Mechanism}

\begin{step} 

\begin{itemize}
    \item[-] Create empty sets $Visited$ and $OftenReapeated$.
    \item[-] $Chaotic \leftarrow 0$.
    \item[-] $contLastSizeChange \leftarrow 0$.
    \item[-] $movingAvg\leftarrow 0$.
    \item[-] $tabuTenure \leftarrow MIN\_TENURE$.
\end{itemize}

\end{step}

\end{block}

}

\end{frame}

\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ \footnotesize

\begin{block}

\underline{\bf Procedure Reaction Mechanism}

\begin{step} 

\begin{itemize}
\item[-] $escape \leftarrow false$.
\item[-] $contLastSizeChange++$.
\item[-] \textbf{If} $U$ is in $Visited$.
    \begin{itemize} \item Call fast reaction. \end{itemize}
\item[-] \textbf{else}
    \begin{itemize} \item Call slow reaction. \end{itemize}
\item[-] \textbf{If} $escape$ is $true$.
    \begin{itemize}
    \item[-] Clear the $Visited$ set.
    \item[-] $chaotic \leftarrow 0$.
    \item[-] Make a random number of moves in $U$.
    \end{itemize}
\end{itemize}

\end{step}

\end{block}
}

\end{frame}


\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ \footnotesize

\begin{block}

\underline{\bf Procedure Fast Reaction}

\begin{step} 

\begin{itemize}
    \item[-] $TamCycle \leftarrow$ present iteration - last visit iteration of $U$.
    \item[-] Increment the number of visits of $U$ and update the iteration of last visit to $U$.
    \item[-] \textbf{If} $TamCycle < CYCLE\_MIN$.
        \begin{itemize}
        \item[-] $movingAvg \leftarrow 0.9 * movingAvg + 0.1 * TamCycle$.
        \item[-] $tabuTenure \leftarrow min(tabuTenure * INCREASE, MAX\_TENURE)$.
        \item[-] $contLastSizeChange \leftarrow 0$.
        \end{itemize}
    \item[-] \textbf{If} number of visits to $U > MAX\_VISITS$ and $U$ is not in $OftenRepeated$
        \begin{itemize}
        \item[-] Insert $U$ in $OftenRepeated$ and increment $chaotic$.
        \item[-] \textbf{If} $chaotic > CHAOS$.
            \begin{itemize}
            \item[-] $escape \leftarrow true$.
            \end{itemize}
        \end{itemize}
\end{itemize}

\end{step}

\end{block}
}

\end{frame}

\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ \footnotesize

\begin{block}

\underline{\bf Procedure Slow Reaction}

\begin{step} 

\begin{itemize}
    \item[-] Insert $U$ in $Visited$ and set the number of visits to $U$ to one and the last iteration of a visit to $U$ to the present iteration.
    \item[-] \textbf{If} $contLastSizeChange > movingAvg$.
        \begin{itemize}
        \item[-] $tabuTenure \leftarrow max(tabuTenure * DECREASE, MIN\_TENURE)$.
        \item[-] $contLastSizeChange \leftarrow 0$.
        \end{itemize}
    \end{itemize}
\end{step}

\end{block}
}

\end{frame}

\begin{frame}<1>
  \frametitle{The Reaction Mechanism}

{ 
	\footnotesize
  \begin{itemize}
  	\item It is clear that implementing this reaction mechanism in a strict way would possibly demand an excessive large amount of memory and/or a very smart data structure regarding compression and access time.

  	
  	\item Instead of keeping the real set of solution, we used a hash table that uses the hash function on the string constructed by the concatenation of the number of vertices covered by exactly by $i$  vertices of the current solution for $i$ in the range from $1$ to $6$.
  	
  	\item Although this has shown to reasonably differ the solutions in our tests, it certainly generates a number of false positive tests.
  	
  	\item But since this a heuristic search, the worst harm would be a bad heuristic behaviour which was not the case, and should seldom be.
  	
  \end{itemize}

}
\end{frame}

\section{Results and Conclusions}

\begin{frame}<1>
  \frametitle{Results and Conclusions}

{ 
	\footnotesize
  \begin{itemize}
  	\item The reactive TS algorithm was implemented in C++ programming language and the experiments were executed on a Pentium 4 with 3.2 GHz.
  	
  	\item We ran the algorithm with and without the reaction mechanism. Those without used a fixed tabu tenure.
  	
  	\item The set of instances for 7 different values of the pair $n$ and $R$, keeping the size of the
alphabet on $3$.

  	\item The runs with the fixed tabu tenure used values 10, 20 and 30, running for this algorithm 10 independent tries for each instance.
  	
  	\item The reactive tabu search used parameters determined in an empirical way after a series of preliminaries experiments.

		\item Also, 10 independent tries were made for each instance, using always the same chosen parameter configuration.
  
  \end{itemize}

}
\end{frame}


\begin{frame}<1>
  \frametitle{Results and Conclusions}

{ 
	\footnotesize
  \begin{block}
  
\underline{\bf Legend}
  \begin{itemize}
  	\item $LB$: lower bounds from section theorical bounds on short coverings.
  	\item $UB$: upper bounds from section theorical bounds on short coverings.
  	\item \textbf{NI}: indicates the number of iterations of the algorithm.
  	\item \textbf{TS}: identifies the Basic Tabu Search results.
  	\item \textbf{RTS}: identifies the Reactive Tabu Search results. 
  	\item $AUB$: stands for the upper bounds found by the algorithms.
  	\item AT(s): labels the average algorithm running time in seconds.

  \end{itemize}
  \end{block}

}
\end{frame}


\begin{frame}<1>
  \frametitle{Results and Conclusions}

\[
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{6}{|c|}{} & \multicolumn{2}{|c|}{\textbf{TS} } & \multicolumn{2}{|c|}{\textbf{RTS}} \\ \hline
$n$ & $q$ & $R$ & $LB$  & $UB$ & \textbf{NI} & $AUB$ & AT(s) & $AUB$ & AT(s) \\  \hline
5 & 3 & 1 &  13  & 40 & 2000 & 13 & 0.064 & 13 & 0.065 \\ \hline
5 & 3 & 2 & 4 & 13 & 1000 & 4 & 0.148 & 4 & 0.150 \\  \hline
6 & 3 & 1 & 32  & 121 & 100000 & 39 & 11.036 & 37 & 11.103 \\ \hline
6 & 3 & 2 & 7  & 40 & 50000 & 8 & 25.654 & 8 & 31.05 \\  \hline
7 & 3 & 1 & 78 & 364 & 200000 & 107 & 94.233 & 105 & 127.94 \\  \hline
7 & 3 & 2  & 13 & 121 & 100000 & 19 & 227.80 & 17 & 267.71 \\ \hline
7 & 3 & 3 & 5 & 40 & 1000 & 7 & 66.02 & 6 & 72.38 \\ \hline
\end{tabular}
\]
\end{frame}


\begin{frame}<1>
  \frametitle{Results and Conclusions}

{ 
	
  \begin{itemize}
  	\item The first two instances were use to test the correctness and minimum quality of the proposed approach, and they found the optimal solution and proved their optimality.
  	
  	\item On the remaining instances, there were only one case where the reactive and the classical TS found the same
value, probably because that both are optimal, and these solutions are easy to find.
  	
  	\item The other 4 seem to be demanding instances. On all of them the reactive approach performed better.

  \end{itemize}

}
\end{frame}


\begin{frame}<1>
  \frametitle{Results and Conclusions}

{ 
	\footnotesize
  \begin{itemize}
  	\item This is a new problem and it is difficult to tell how hard they are to repeat, this will be left for future research of other researchers in the area.
  	
  	\item We are convinced that our approach is a strong one. The reason for this statement comes from the more classical problem of finding $R-covering$ codes instead of $R-short-covering$ codes.
  	
  	\item The reactive TS proposed here was also applied on $R-covering$, obtaining execellent results.
  	
  	\item The reactive TS was able to repeatedly find the best known solution, including the 73 value for the $K_{3}(6,1)$ and the 186 value for the $K_{3}(7,1)$.
  
  \end{itemize}

}
\end{frame}


\end{document}
